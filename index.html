<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Nisarga Kadam | AI + Security</title>
    <style>
        body {
            margin: 0;
            font-family: 'Inter', sans-serif;
            background-color: #ffffff;
            color: #2e1a47;
        }
        header {
            text-align: center;
            padding: 80px 20px;
        }
        h1 {
            font-size: 3rem;
            margin-bottom: 10px;
            color: #4b2c75;
        }
        h2 {
            font-weight: 300;
            font-size: 1.2rem;
            color: #6a4c9c;
        }
        section {
            max-width: 800px;
            margin: 40px auto;
            padding: 0 20px;
            line-height: 1.7;
        }
        a {
            color: #7a3ff6;
            font-weight: 600;
            text-decoration: none;
        }
        .projects {
            margin-top: 20px;
        }
        .project-card {
            border: 1px solid #e9ddff;
            padding: 20px;
            border-radius: 12px;
            margin-bottom: 20px;
            transition: 0.2s;
        }
        .project-card:hover {
            transform: translateY(-3px);
            box-shadow: 0px 10px 20px rgba(122, 63, 246, 0.1);
        }
    </style>
</head>
<body>
    <header>
        <h1>Nisarga Kadam</h1>
        <h2>AI ‚Ä¢ Security ‚Ä¢ Data Systems</h2>
    </header>

    <section>
        <p>
            I'm a CS grad student + data analyst exploring the intersection of 
            <strong>machine learning, security, and real-world systems risk</strong>. 
            I build projects that make AI safer, more interpretable, and more aligned with 
            how people actually use technology.
        </p>

        <p>
            Currently exploring:<br>
            ‚Ä¢ ML security vulnerabilities (data poisoning, evasion) <br>
            ‚Ä¢ Trust + safety for consumer AI products <br>
            ‚Ä¢ Detection systems for authenticity, fraud, and anomalous behavior <br>
        </p>

        <h3>Featured Projects</h3>
        <div class="projects">
            
            <div class="project-card">
                <h3>üõ° Amazon Review Fraud Detection (ML)</h3>
                <p>
                    Built an ML pipeline analyzing real Amazon product reviews to detect 
                    low-quality or suspicious content. Used NLP embeddings + anomaly 
                    detection to flag manipulative behavior.
                </p>
                <a href="https://github.com/nisargakadam/Amazon-Fake-Review-Detection">View Project ‚Üí</a>
            </div>

            <div class="project-card">
                <h3>üèÄ Courtside Bestie ‚Äî LLM NBA Explainer</h3>
                <p>
                    A conversational basketball ‚Äúexplainer bot‚Äù exploring model reasoning, 
                    prompt safety, and user-context alignment using nba_api and custom evaluation.
                </p>
                <a href="https://github.com/nisargakadam/CourtsideBestie">View Project ‚Üí</a>
            </div>

            <div class="project-card">
                <h3>üìä ETL Pipeline for Large-Scale Amazon Data</h3>
                <p>
                    Designed a secure, reproducible ETL pipeline using Polars + DuckDB 
                    to process millions of reviews while ensuring data lineage and trust.
                </p>
                <a href="https://github.com/nisargakadam/amazon-etl">View Project ‚Üí</a>
            </div>
        </div>
    </section>
</body>
</html>
