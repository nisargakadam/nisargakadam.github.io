<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Nisarga Kadam | AI ¬∑ Security ¬∑ Data</title>

    <style>
        body {
            margin: 0;
            font-family: 'Inter', sans-serif;
            background-color: #ffffff;
            color: #2e1a47;
        }
        header {
            text-align: center;
            padding: 80px 20px 40px 20px;
        }
        h1 {
            font-size: 3rem;
            margin-bottom: 10px;
            color: #4b2c75;
        }
        h2 {
            font-weight: 300;
            font-size: 1.3rem;
            color: #6a4c9c;
        }
        section {
            max-width: 900px;
            margin: 40px auto;
            padding: 0 20px;
            line-height: 1.7;
        }
        a {
            color: #7a3ff6;
            font-weight: 600;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }

        /* Project card styling */
        .projects {
            margin-top: 20px;
        }
        .project-card {
            border: 1px solid #e9ddff;
            padding: 20px;
            border-radius: 14px;
            margin-bottom: 25px;
            transition: 0.2s ease;
            background: #faf6ff;
        }
        .project-card:hover {
            transform: translateY(-4px);
            box-shadow: 0 10px 25px rgba(122, 63, 246, 0.12);
        }

        h3 {
            color: #4b2c75;
            margin-bottom: 8px;
        }
    </style>
</head>

<body>

    <!-- HEADER -->
    <header>
        <h1>Nisarga Kadam</h1>
        <h2>AI ¬∑ Security ¬∑ Data Systems</h2>
    </header>

    <!-- INTRO SECTION -->
    <section>
        <p>
            I'm a CS graduate student and data analyst exploring the intersection of 
            <strong>AI security, machine learning, and trust & integrity systems</strong>.
            I build projects that analyze how models behave under real-world conditions ‚Äî
            focusing on robustness, risk, and data quality.
        </p>

        <p>Currently exploring:</p>
        <ul>
            <li>LLM reasoning failures & robustness evaluation</li>
            <li>Fraud / anomaly detection in digital platforms</li>
            <li>Interpretability & trustworthiness of AI predictions</li>
            <li>Data integrity and responsible ML systems</li>
        </ul>

        <!-- PROJECTS SECTION -->
        <h3>Featured Projects</h3>
            <div class="projects">
            
                <!-- Fake Review Detection -->
                <div class="project-card">
                    <h3>üõ° Fake Review Detection (AI Trust & Integrity) ‚Äî Dec 2024</h3>
                    <p>
                        Built an NLP + HuggingFace BLAiR pipeline detecting fraudulent Amazon 
                        reviews with an <strong>81% F1 score</strong>. Uncovered behavioral patterns 
                        (e.g., short overly-positive reviews 32% more likely to be fake) and 
                        visualized anomaly clusters in Tableau to strengthen platform trust.
                    </p>
                    <a href="https://github.com/nisargakadam/Amazon-Fake-Review-Detection">View Project ‚Üí</a>
                </div>
            
                <!-- NBA Playoff Prediction -->
                <div class="project-card">
                    <h3>üèÄ NBA Playoff Prediction (Pattern & Outlier Analysis) ‚Äî May 2025</h3>
                    <p>
                        Trained and evaluated a Random Forest model on <strong>96+ playoff logs</strong> 
                        to identify outlier performance patterns and surface the most predictive KPIs 
                        influencing game outcomes. Explored model consistency, variance, and 
                        sensitivity across team contexts.
                    </p>
                    <a href="https://github.com/nisargakadam/NBA-Playoff-Predictor">View Project ‚Üí</a>
                </div>
            
                <!-- Government Spending & FLFP -->
                <div class="project-card">
                    <h3>üìä Government Spending & Female Labor Participation (Bias & Data Integrity Study) ‚Äî May 2023</h3>
                    <p>
                        Applied Ridge Regression with grid search to analyze government spending 
                        impacts while ensuring data integrity through multicollinearity checks, 
                        consistent feature selection, and reproducible preprocessing pipelines. 
                        Highlighted policy implications and structural bias considerations.
                    </p>
                    <a href="https://github.com/nisargakadam/Govt-Spending-FLFP">View Project ‚Üí</a>
                </div>
            
            </div>


        </div>
    </section>

</body>
</html>
